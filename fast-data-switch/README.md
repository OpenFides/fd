# Fast Data Switch Adaptor

## 简述

Fast Data Switch Adaptor是一个异构的数据交换工具，致力于使用一个工具解决不同数据源（JDBC、FILE、Kafka、FTP等）之间数据交换的问题。

Fast Data Switch Adaptor在设计上采用“框架+插件”的结构，具有较好的扩展性。框架相当于数据缓冲区，实现单机模式（基于disruptor），分布式（基于消息机制），插件则为访问不同的数据源和处理提供实现。

## 特性

1. 极简的使用体验
   绿色版本，跨平台部署运行，WebUI操作
3. 异构数据源之间交换
4. 丰富的数据转换功能
   基于插件模式，易扩展，除了提供数据快照搬迁功能之外，还提供了丰富数据转换的功能，让数据在传输过程中可以轻松完成数据脱敏，补全，过滤等数据转换功能，另外还提供了自动groovy函数，让用户自定义转换函数。
5. 可靠的数据质量监控
提供作业全链路的流量、数据量运行时监控，将作业本身状态、数据流量、数据速度、执行进度等信息进行全面的展示，让用户可以实时了解作业状态。并可在作业执行过程中智能判断源端和目的端的速度对比情况，给予用户更多性能排查信息。
6. 提供脏数据探测
在数据的传输过程中，必定会由于各种原因导致很多数据传输报错(比如类型转换错误)，提供脏数据收集让用户准确把控数据质量大关！

精准的速度控制
提供了包括通道(并发)、记录流、字节流三种流控模式，可以随意控制你的作业速度，让你的作业在库可以承受的范围内达到最佳的同步速度

健壮的容错机制

  
## 设计理念

1. 一切皆KV
   1. 配置文件：使用Map<String,Object>
   2. 处理数据：使用Map<String,Object>
2. 一切皆管道
   1. 数据读取（Reader）负责读取外部数据的管道
   2. 数据传送（Channel）负责数据的暂存与传送
   3. 数据处理（Process）负责数据的过滤，修改等
   4. 数据写入（Writer)负责数据的落地
3. 插件模式：数据读取、处理和数据写入均基于插件实现。
4. 事件监听模式: 数据的交换使用高性能环形数据缓冲区实现调整、异步的数据交换。
5. 在分布式时Master负责高度与状态监控，各子节点负责数据读取，处理与写入。

## 管道设计

数据管道需要有以下功能：

1. init 配置数据源
2. scheme 获取元数据
3. collect 流转到下个管道